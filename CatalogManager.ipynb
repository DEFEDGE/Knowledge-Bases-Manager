{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installation of Python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import of libraries and definition of functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "123"
    }
   },
   "outputs": [],
   "source": [
    "from stix2 import FileSystemStore, FileSystemSource\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from neo4j import GraphDatabase, Result\n",
    "from yfiles_jupyter_graphs import GraphWidget\n",
    "from html2text import html2text as h2t\n",
    "import re\n",
    "from functools import reduce\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# neo4j setup\n",
    "load_dotenv()\n",
    "URI_NEO4J = os.getenv(\"URI_NEO4J\")\n",
    "USER_NEO4J = os.getenv(\"USER_NEO4J\")\n",
    "PASS_NEO4J = os.getenv(\"PASS_NEO4J\")\n",
    "\n",
    "stix_path = './capec_stix'\n",
    "attack_pattern_path = f'{stix_path}/attack-pattern'\n",
    "fs = FileSystemStore(stix_dir=stix_path, bundlify=False)\n",
    "fs_source = FileSystemSource(stix_dir=stix_path)\n",
    "\n",
    "macm_file = \"Wordpress.macm\"\n",
    "\n",
    "# pandas setup\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('max_colwidth', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definition of data loading functions in dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "123"
    }
   },
   "outputs": [],
   "source": [
    "def string_to_list(string: str, sepator=r'[ ,]+'):\n",
    "    if string is None:\n",
    "        return None\n",
    "    else:\n",
    "        return re.split(sepator, string)\n",
    "\n",
    "def string_to_int_list(string: str, sepator=r'[ ,]+'):\n",
    "    if string in [None, '', 'None']:\n",
    "        return None\n",
    "    else:\n",
    "        return [int(x) for x in re.split(sepator, string)]\n",
    "    \n",
    "def sub_string(string):\n",
    "    if string is None:\n",
    "        return None\n",
    "    else:\n",
    "        subs = {'*': '', '#': ''}\n",
    "        string = h2t(str(string))   # convert html in certain columns to text\n",
    "        string = string.translate(str.maketrans(subs))\n",
    "        string = re.sub(r'(\\S)\\n(\\S)', r'\\1 \\2', string)\n",
    "        string = string.replace('\\n ', '\\n')\n",
    "        return string\n",
    "\n",
    "def list_to_string(list: list, sepator='\\n\\n'):\n",
    "    if list is None:\n",
    "        return None\n",
    "    else:\n",
    "        return sepator.join(list)\n",
    "\n",
    "def dict_to_string(dict: dict):\n",
    "    if dict is None:\n",
    "        return None\n",
    "    else:\n",
    "        return '\\n\\n'.join([f\"{k}: {v}\" for k, v in dict.items()])\n",
    "    \n",
    "def external_references_to_string(list: list):\n",
    "    output = ''\n",
    "    if list is None:\n",
    "        return None\n",
    "    else:\n",
    "        for reference in list:\n",
    "            for key in reference:\n",
    "                output += f\"{key}: {reference[key]}\\n\"\n",
    "            output += '\\n'\n",
    "        output = output[:-2] # remove last \\n\\n\n",
    "        return output\n",
    "\n",
    "def convert_column_to_text(df: pd.DataFrame):\n",
    "    for column in ['x_capec_can_follow_refs', 'x_capec_domains', 'object_marking_refs', 'x_capec_prerequisites', 'x_capec_alternate_terms', 'x_capec_can_precede_refs', 'x_capec_resources_required', 'x_capec_example_instances']:\n",
    "        df[column] = df[column].apply(lambda x: list_to_string(x))\n",
    "\n",
    "    for column in ['description','x_capec_execution_flow', 'x_capec_extended_description', 'x_capec_example_instances', 'x_capec_resources_required']:\n",
    "        df[column] = df[column].apply(lambda x: sub_string(x))\n",
    "\n",
    "    for column in ['x_capec_consequences', 'x_capec_skills_required']:\n",
    "        df[column] = df[column].apply(lambda x: dict_to_string(x))\n",
    "\n",
    "    for column in ['external_references']:\n",
    "        df[column] = df[column].apply(lambda x: external_references_to_string(x))\n",
    "    return df\n",
    "\n",
    "def convert_column_to_text_4_panel(df: pd.DataFrame):\n",
    "    for column in ['x_capec_consequences', 'x_capec_skills_required']:\n",
    "        df[column] = df[column].apply(lambda x: dict_to_string(x))\n",
    "\n",
    "    for column in ['external_references']:\n",
    "        df[column] = df[column].apply(lambda x: external_references_to_string(x))\n",
    "    return df\n",
    "\n",
    "def truncate_string_middle(s, n):\n",
    "    if len(s) <= n:\n",
    "        # string is already short-enough\n",
    "        return s\n",
    "    # half of the size, minus the 3 .'s\n",
    "    n_2 = int(n) // 2 - 3\n",
    "    # whatever's left\n",
    "    n_1 = n - n_2 - 3\n",
    "    return '{0}...{1}'.format(s[:n_1], s[-n_2:])\n",
    "\n",
    "def convert_ids_to_capec_ids(df: pd.DataFrame):\n",
    "    df['capec_id'] = df['external_references'].apply(lambda x: int(x[0]['external_id'].split('-')[1]) if x[0]['source_name'] == 'capec' else None)\n",
    "    df['capec_childs_id'] = df['x_capec_parent_of_refs'].apply(lambda ids: [int(df.loc[id]['capec_id']) for id in ids] if ids is not None or [] else None)\n",
    "    df['capec_parents_id'] = df['x_capec_child_of_refs'].apply(lambda ids: [int(df.loc[id]['capec_id']) for id in ids] if ids is not None or [] else None)\n",
    "    return df\n",
    "\n",
    "def highlight_attack_patterns(s):\n",
    "    if s.x_capec_abstraction == 'Meta':\n",
    "        return ['background-color: #5CC0FF']*len(s)\n",
    "    elif s.x_capec_abstraction == 'Standard':\n",
    "        return ['background-color: #85D0FF']*len(s)\n",
    "    elif s.x_capec_abstraction == 'Detailed':\n",
    "        return ['background-color: #ADE0FF']*len(s)\n",
    "    else:\n",
    "        return ['']\n",
    "\n",
    "def style_df(df_styler):\n",
    "    border = '1px solid black !important'\n",
    "    df_styler.set_table_styles([\n",
    "        {'selector': 'th', 'props': [('text-align', 'left'), ('border', border)]},\n",
    "        {'selector': 'td tbody', 'props': [('border', border)]},\n",
    "        {'selector': 'td', 'props': [('text-align', 'left'), ('border', border), ('max-width', '400px !important'), ('word-wrap', 'break-word'), ('vertical-align', 'top'), ('white-space', 'pre-line')]}\n",
    "    ])\n",
    "    df_styler.apply(highlight_attack_patterns, axis=1)\n",
    "    return df_styler\n",
    "    \n",
    "def capec_abstraction_sort(df: pd.DataFrame):\n",
    "    sorter = ['Meta', 'Standard', 'Detailed']\n",
    "    df['x_capec_abstraction'] = pd.Categorical(df['x_capec_abstraction'], categories=sorter, ordered=True)\n",
    "    df = df.sort_values(['x_capec_abstraction', 'capec_id'], ascending=[True, True])\n",
    "    return df.style.pipe(style_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "123"
    }
   },
   "outputs": [],
   "source": [
    "def load_threat_catalog(filename):\n",
    "    df = pd.read_excel(filename, sheet_name=\"Threat Components\", header=0)\n",
    "    df.replace(np.nan, None, inplace=True) # replace NaN with None\n",
    "    df.set_index('TID', inplace=True)\n",
    "    df = df.astype('str')\n",
    "    columns_to_convert = ['CapecMeta', 'CapecStandard', 'CapecDetailed']\n",
    "    for column in columns_to_convert:\n",
    "        df[column] = df[column].apply(lambda x: string_to_list(x))\n",
    "    df['Asset'] = df['Asset'].apply(lambda x: x.replace('.', '_'))\n",
    "    return df\n",
    "\n",
    "def load_attack_patterns():\n",
    "    attack_pattern_list = []\n",
    "    for attack_pattern in [x.removesuffix(\".json\") for x in os.listdir(attack_pattern_path)]:\n",
    "        ap = fs.get(attack_pattern)\n",
    "        attack_pattern_list.append(ap)\n",
    "    attack_pattern_df = pd.DataFrame(attack_pattern_list)\n",
    "    attack_pattern_df.set_index('id', inplace=True)\n",
    "    attack_pattern_df.replace(np.nan, None, inplace=True) # replace NaN with None\n",
    "    attack_pattern_df = convert_ids_to_capec_ids(attack_pattern_df)\n",
    "    attack_pattern_df.set_index('capec_id', inplace=True)\n",
    "    attack_pattern_df.drop(['x_capec_parent_of_refs', 'x_capec_child_of_refs'], axis=1, inplace=True)\n",
    "    attack_pattern_df.index = pd.CategoricalIndex(attack_pattern_df.index, sorted(attack_pattern_df.index.to_list(), key=lambda x: int(x)))\n",
    "    return attack_pattern_df\n",
    "\n",
    "def dataframe_to_str(df: pd.DataFrame):\n",
    "    df_str = df.copy() # copy the dataframe\n",
    "    df_str = convert_column_to_text(df_str) # convert all columns to text\n",
    "    df_str = df_str.astype(str).copy() # convert all columns to string\n",
    "    return df_str\n",
    "\n",
    "def get_child_attack_patterns_by_id(parent_id, attack_pattern_df: pd.DataFrame):\n",
    "    try:\n",
    "        return attack_pattern_df.loc[parent_id].get('capec_childs_id') or []\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def get_child_attack_patterns_recursive(parent_id, attack_pattern_df: pd.DataFrame) -> list:\n",
    "    childs = get_child_attack_patterns_by_id(parent_id, attack_pattern_df)\n",
    "    if childs is None:\n",
    "        return []\n",
    "    else:\n",
    "        for child in childs:\n",
    "            childs += get_child_attack_patterns_recursive(child, attack_pattern_df)\n",
    "        return childs\n",
    "\n",
    "def get_child_attack_patterns(parent_ids, attack_pattern_df: pd.DataFrame, show_tree=False, show_columns=['name', 'capec_parents_id', 'capec_childs_id', 'x_capec_abstraction', 'description', 'x_capec_extended_description']):\n",
    "    if type(parent_ids) is not list: parent_ids = [parent_ids]\n",
    "    childs = [parent_id for parent_id in parent_ids]\n",
    "    if show_tree:\n",
    "        childs += [child for parent_id in parent_ids for child in get_child_attack_patterns_recursive(parent_id, attack_pattern_df)]\n",
    "    childs = list(set(childs))\n",
    "    try:\n",
    "        response = attack_pattern_df.loc[childs][show_columns]\n",
    "        return response\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def query_attack_patterns(attack_pattern_df: pd.DataFrame, keywords, search_columns:list=['description'], ap_type:list=['Meta', 'Standard', 'Detailed'], show_columns=['name', 'capec_parents_id', 'capec_childs_id', 'x_capec_abstraction', 'description', 'x_capec_extended_description'], query_type='or'):\n",
    "    if query_type == 'or':\n",
    "        keywords = '|'.join(keywords)\n",
    "    elif query_type == 'and':\n",
    "        keywords = r'(?=.*' + r')(?=.*'.join(keywords) + r')'\n",
    "    else:\n",
    "        raise Exception('query_type must be \"or\" or \"and\"')\n",
    "    inds = [attack_pattern_df[x].str.lower().str.contains(keywords.lower()) for x in search_columns]\n",
    "    type_inds = [attack_pattern_df['x_capec_abstraction'].isin([x]) for x in ap_type]\n",
    "    response = attack_pattern_df[(reduce(lambda x, y: x | y, inds)) & (reduce(lambda x, y: x | y, type_inds))][show_columns].sort_values(by=['x_capec_abstraction'])\n",
    "    return response\n",
    "\n",
    "def read_macm(driver):\n",
    "    macm_df = driver.execute_query(\"MATCH (asset) RETURN asset.component_id, asset.application, asset.name, asset.type, asset.app_id\", database_='macm', result_transformer_=Result.to_df)\n",
    "    macm_df.columns = ['Component ID', 'Application', 'Name', 'Type', 'App ID']\n",
    "    return macm_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definition of data loading functions in Neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "31"
    }
   },
   "outputs": [],
   "source": [
    "def clear_database(driver, database):\n",
    "    driver.execute_query(\"MATCH (n) DETACH DELETE n\", database_=database)\n",
    "\n",
    "def create_capec_db(driver, attack_pattern_df: pd.DataFrame, database=\"capec\", show_parent_relationship=True):\n",
    "    attack_pattern_df_str = dataframe_to_str(attack_pattern_df)\n",
    "    for index, row in attack_pattern_df_str.iterrows():\n",
    "        driver.execute_query('''\n",
    "                MERGE (a:'''+ row['x_capec_abstraction'] + ''' {\n",
    "                        Capec_Id:$id,\n",
    "                        Name:$name,\n",
    "                        Created: $created,\n",
    "                        Created_By_Ref:$created_by_ref, \n",
    "                        Description:$description,\n",
    "                        External_References:$external_references,\n",
    "                        Modified:$modified,\n",
    "                        Object_Marking_Refs:$object_marking_refs,\n",
    "                        Revoked:$revoked,\n",
    "                        Spec_Version:$spec_version,\n",
    "                        Type:$type, \n",
    "                        Abstraction:$x_capec_abstraction,\n",
    "                        Alternate_Terms:$x_capec_alternate_terms,\n",
    "                        Can_Follow_Refs:$x_capec_can_follow_refs,\n",
    "                        Can_Precede_Refs:$x_capec_can_precede_refs,\n",
    "                        Child_Of_Refs:$capec_parents_id,\n",
    "                        Consequences:$x_capec_consequences,\n",
    "                        Domains:$x_capec_domains,\n",
    "                        Example_Instances:$x_capec_example_instances,\n",
    "                        Execution_Flow:$x_capec_execution_flow,\n",
    "                        Extended_Description:$x_capec_extended_description,\n",
    "                        Likelihood_Of_Attack:$x_capec_likelihood_of_attack,\n",
    "                        Parent_Of_Refs:$capec_childs_id,\n",
    "                        Peer_Of_Refs:$x_capec_peer_of_refs,\n",
    "                        Prerequisites:$x_capec_prerequisites,\n",
    "                        Resources_Required:$x_capec_resources_required,\n",
    "                        Skills_Required:$x_capec_skills_required,\n",
    "                        Status:$x_capec_status,\n",
    "                        Typical_Severity:$x_capec_typical_severity,\n",
    "                        Version:$x_capec_version\n",
    "                    })\n",
    "                ''', parameters_={'id': index} | row.to_dict(), database_=database)\n",
    "    if show_parent_relationship:\n",
    "        parents = [\"Meta\", \"Standard\"]\n",
    "        for parent_type in parents:\n",
    "            for parent in attack_pattern_df.query(f\"x_capec_abstraction == '{parent_type}'\").index:\n",
    "                parent_attack_pattern = attack_pattern_df.loc[parent]\n",
    "                for child in get_child_attack_patterns_by_id(parent, attack_pattern_df):\n",
    "                    if child in attack_pattern_df.index:\n",
    "                        driver.execute_query(f\"\"\"\n",
    "                            MATCH (parent {{Capec_Id: {parent_attack_pattern.name}}}),\n",
    "                                    (child {{Capec_Id: {attack_pattern_df.loc[child].name}}})\n",
    "                            MERGE (parent)-[:parent_of]->(child)\n",
    "                        \"\"\", database_=database)\n",
    "\n",
    "def create_threat_catalog_db(driver, threat_catalog_df: pd.DataFrame, database=\"threats\"):\n",
    "    for index, row in threat_catalog_df.iterrows():\n",
    "        driver.execute_query('''\n",
    "                MERGE (a:'''+ row['Asset'] + ''' {\n",
    "                        TID:$TID,\n",
    "                        Asset:$Asset,\n",
    "                        Threat:$Threat,\n",
    "                        Description:$Description,\n",
    "                        STRIDE:$STRIDE,\n",
    "                        Compromised:$Compromised,\n",
    "                        PreConfidentiality:$PreC,\n",
    "                        PreIntegrity:$PreI,\n",
    "                        PreAvailability:$PreA,\n",
    "                        PreCondition:$Precondition,\n",
    "                        PostConfidentiality:$PostC,\n",
    "                        PostIntegrity:$PostI,\n",
    "                        PostAvailability:$PostA,\n",
    "                        PostCondition:$PostCondition,\n",
    "                        CapecMeta:$CapecMeta,\n",
    "                        CapecStandard:$CapecStandard,\n",
    "                        CapecDetailed:$CapecDetailed\n",
    "                    })\n",
    "                ''', parameters_={'TID': index} | row.to_dict(), database_=database)\n",
    "        \n",
    "def create_unified_db(driver, attack_pattern_df: pd.DataFrame, threat_catalog_df: pd.DataFrame, database=\"capecthreats\"):\n",
    "    create_capec_db(driver, attack_pattern_df, database)\n",
    "    create_threat_catalog_db(driver, threat_catalog_df, database)\n",
    "    for index, row in threat_catalog_df.iterrows():\n",
    "        for capec_id in row['CapecMeta'] + row['CapecStandard'] + row['CapecDetailed']:\n",
    "            if capec_id != 'None':\n",
    "                driver.execute_query(f\"\"\"\n",
    "                    MATCH (threat {{TID: \"{index}\"}}),\n",
    "                            (capec {{Capec_Id: {capec_id}}})\n",
    "                    CALL apoc.create.relationship(threat, \"has_capec_\" + capec.Abstraction, NULL, capec) YIELD rel\n",
    "                    RETURN rel\n",
    "                \"\"\", database_=database)\n",
    "\n",
    "def create_enhanched_macm_db(driver, attack_pattern_df: pd.DataFrame, threat_catalog_df: pd.DataFrame, macm_df:pd.DataFrame, macm_file, database=\"emacm\"):\n",
    "    load_macm(macm_file, driver, database)\n",
    "    for index, row in macm_df.iterrows():\n",
    "        related_threat_catalog_df = threat_catalog_df[threat_catalog_df['Asset'] == row['Type'].replace('.', '_')]\n",
    "        related_attack_pattern = [int(id) for ids in related_threat_catalog_df['CapecMeta'].to_list() + related_threat_catalog_df['CapecStandard'].to_list() + related_threat_catalog_df['CapecDetailed'].to_list() for id in ids if id != 'None']\n",
    "        related_attack_pattern = list(set(related_attack_pattern))\n",
    "        related_attack_pattern_df = attack_pattern_df.loc[related_attack_pattern]\n",
    "        create_capec_db(driver, related_attack_pattern_df, database, show_parent_relationship=False)\n",
    "        for capec_id in related_attack_pattern:\n",
    "            if capec_id != 'None':\n",
    "                driver.execute_query(f\"\"\"\n",
    "                    MATCH (macm {{component_id: \"{row['Component ID']}\"}}),\n",
    "                            (capec {{Capec_Id: {capec_id}}})\n",
    "                    CALL apoc.create.relationship(macm, \"has_capec_\" + capec.Abstraction, NULL, capec) YIELD rel\n",
    "                    RETURN rel\n",
    "                \"\"\", database_=database)\n",
    "\n",
    "def load_macm(filename, driver, database='macm'):\n",
    "    with open(filename, 'r') as f:\n",
    "        query = f.read()\n",
    "        driver.execute_query(query, database_=database)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Attack Patterns and Threat Catalog into DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "13"
    }
   },
   "outputs": [],
   "source": [
    "attack_pattern_df = load_attack_patterns()\n",
    "threat_catalog_df = load_threat_catalog(\"ThreatCatalogComplete.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the DataFrame columns to strings for compatibility with Neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "31"
    }
   },
   "outputs": [],
   "source": [
    "attack_pattern_df_str = dataframe_to_str(attack_pattern_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading databases into Neo4j"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connecting to the Neo4j database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "231"
    }
   },
   "outputs": [],
   "source": [
    "driver = GraphDatabase.driver(URI_NEO4J, auth=(USER_NEO4J, PASS_NEO4J))\n",
    "driver.verify_connectivity()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creation of the Capec graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "3"
    }
   },
   "outputs": [],
   "source": [
    "clear_database(driver, 'capec')\n",
    "create_capec_db(driver, attack_pattern_df=attack_pattern_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creation of the Threat Catalog graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "3"
    }
   },
   "outputs": [],
   "source": [
    "clear_database(driver, \"threats\")\n",
    "create_threat_catalog_db(driver, threat_catalog_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creation of the Capec-Threat Catalog graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "3"
    }
   },
   "outputs": [],
   "source": [
    "clear_database(driver, \"capecthreats\")\n",
    "create_unified_db(driver, threat_catalog_df=threat_catalog_df, attack_pattern_df=attack_pattern_df, database=\"capecthreats\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the MACM data into Neo4j"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the MACM of the system under examination into Neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "3"
    }
   },
   "outputs": [],
   "source": [
    "clear_database(driver, \"macm\")\n",
    "load_macm(macm_file, driver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with driver.session(database=\"macm\") as session:\n",
    "    query_out = session.run(\"MATCH a=((n)-[r1]->(p)) RETURN a\").graph()\n",
    "macm_graph = GraphWidget(graph=query_out)\n",
    "macm_graph.directed = True\n",
    "macm_graph.set_sidebar(enabled=True, start_with=\"Neighborhood\")\n",
    "macm_graph.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Representation of the Capec graph with an external library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [],
   "source": [
    "node_styles = {\n",
    "    \"Meta\": {\"color\": \"red\", \"label\": \"Name\"},\n",
    "    \"Standard\": {\"color\": \"blue\", \"label\": \"Name\", \"shape\": \"box\"},\n",
    "    \"Detailed\": {\"color\": \"green\", \"label\": \"Name\", \"shape\": \"hexagon\"},\n",
    "}\n",
    "\n",
    "with driver.session(database=\"capec\") as session:\n",
    "    query_out = session.run(\"MATCH a=((n)-[r1]->(p)) RETURN a\").graph()\n",
    "graph = GraphWidget(graph=query_out)\n",
    "graph.directed = True\n",
    "graph.set_sidebar(enabled=True, start_with=\"Neighborhood\")\n",
    "graph.set_node_styles_mapping(lambda index, node: node_styles.get(node[\"properties\"][\"Abstraction\"], {}))\n",
    "graph.set_node_label_mapping(lambda index, node : truncate_string_middle(node[\"properties\"][node_styles.get(node[\"properties\"][\"label\"], {\"label\":\"label\"})[\"label\"]], 15))\n",
    "graph.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query in the Capec catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [],
   "source": [
    "query_attack_patterns(attack_pattern_df_str, search_columns=['description', 'name'], keywords=['communication', 'network', 'interaction'], ap_type=['Meta'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [],
   "source": [
    "query_attack_patterns(attack_pattern_df_str, search_columns=['name', 'description'], keywords=['node', 'forward'], query_type='and')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [],
   "source": [
    "get_child_attack_patterns(169, attack_pattern_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GUI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interactive interface for searching information in the Capec catalog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML\n",
    "import yake\n",
    "\n",
    "# YAKE setup\n",
    "language = \"en\"\n",
    "max_ngram_size = 3\n",
    "deduplication_threshold = 0.9\n",
    "numOfKeywords = 20\n",
    "custom_kw_extractor = yake.KeywordExtractor(lan=language, n=max_ngram_size, dedupLim=deduplication_threshold, top=numOfKeywords, features=None)\n",
    "\n",
    "display(HTML('''\n",
    "    <style>\n",
    "        .myStyle { font-weight: bold; }\n",
    "    </style>\n",
    "'''))\n",
    "\n",
    "column_to_search = attack_pattern_df.columns.to_list()\n",
    "\n",
    "clear_button = widgets.Button(\n",
    "    description='Clear',\n",
    "    disabled=False,\n",
    "    button_style='danger',\n",
    "    tooltip='Clear',\n",
    "    icon='trash',\n",
    "    layout=widgets.Layout(width='auto', height='auto')\n",
    ")\n",
    "\n",
    "search_id_tags = widgets.TagsInput(\n",
    "    value=[],\n",
    "    placeholder='Search ID',\n",
    "    description='ID',\n",
    "    disabled=False,\n",
    "    layout=widgets.Layout(width='200px', height='auto')\n",
    ")\n",
    "\n",
    "show_tree_toggle = widgets.ToggleButtons(\n",
    "    options=[True, False],\n",
    "    value=False,\n",
    "    description='Show Childs',\n",
    "    disabled=False,\n",
    "    button_style='info',\n",
    "    tooltip='Show Tree',\n",
    "    icon='check',\n",
    "    layout=widgets.Layout(width='auto', height='auto', justify_content='center', align_items='center', flex_flow='column', display='flex'),\n",
    "    style=widgets.ToggleButtonsStyle(button_width='auto', font_weight='bold')\n",
    ")\n",
    "\n",
    "show_all_toggle = widgets.ToggleButtons(\n",
    "    options=[True, False],\n",
    "    value=False,\n",
    "    description='Show All',\n",
    "    disabled=False,\n",
    "    button_style='info',\n",
    "    tooltip='Show All',\n",
    "    icon='check',\n",
    "    layout=widgets.Layout(width='auto', height='auto', justify_content='center', align_items='center', flex_flow='column', display='flex'),\n",
    "    style=widgets.ToggleButtonsStyle(button_width='auto', font_weight='bold')\n",
    ")\n",
    "\n",
    "id_label = widgets.Label(value='ID')\n",
    "\n",
    "search_id_box_clr = widgets.HBox([clear_button, search_id_tags], layout=widgets.Layout(align_items='center', width='auto', justify_content='center'))\n",
    "search_id_box = widgets.VBox([id_label, search_id_box_clr], layout=widgets.Layout(align_items='center', width='auto', justify_content='center'))\n",
    "\n",
    "search_type_toggle = widgets.ToggleButtons(\n",
    "    options=['or', 'and'],\n",
    "    value='or',\n",
    "    description='Search Type',\n",
    "    disabled=False,\n",
    "    button_style='info',\n",
    "    tooltips=['Search using OR', 'Search using AND'],\n",
    "    layout=widgets.Layout(width='auto', height='auto', justify_content='center', align_items='center', flex_flow='column', display='flex'),\n",
    "    style=widgets.ToggleButtonsStyle(button_width='auto', font_weight='bold')\n",
    ")\n",
    "\n",
    "search_abstraction_sel = widgets.SelectMultiple(\n",
    "    options=['Meta', 'Standard', 'Detailed'],\n",
    "    value=['Meta', 'Standard', 'Detailed'],\n",
    "    rows=3,\n",
    "    description='Abstraction',\n",
    "    disabled=False,\n",
    "    layout=widgets.Layout(width='auto', height='fit-content', justify_content='center', align_items='center', flex_flow='column', display='flex')\n",
    ")\n",
    "\n",
    "search_columns_sel = widgets.SelectMultiple(\n",
    "    options=column_to_search,\n",
    "    value=column_to_search,\n",
    "    rows=5,\n",
    "    description='Columns',\n",
    "    disabled=False,\n",
    "    layout=widgets.Layout(width='auto', height='auto', justify_content='center', align_items='center', flex_flow='column', display='flex')\n",
    ")\n",
    "\n",
    "show_columns = widgets.SelectMultiple(\n",
    "    options=column_to_search,\n",
    "    value=['name', 'capec_parents_id', 'capec_childs_id', 'x_capec_abstraction', 'description', 'x_capec_extended_description'],\n",
    "    rows=5,\n",
    "    description='Columns to show',\n",
    "    disabled=False,\n",
    "    layout=widgets.Layout(width='fit-content', height='auto', justify_content='center', align_items='center', flex_flow='column', display='flex')\n",
    ")\n",
    "\n",
    "keywords_label = widgets.Label(value='Keywords')\n",
    "\n",
    "search_keyword_tag = widgets.TagsInput(\n",
    "    placeholder='Enter keyword',\n",
    "    value=[],\n",
    "    allow_duplicates=False,\n",
    "    layout=widgets.Layout(width='fit-parent', height='auto', justify_self='center', align_self='center')\n",
    ")\n",
    "\n",
    "keyword_description = widgets.Textarea(\n",
    "    placeholder='Enter description',\n",
    "    value='',\n",
    "    disabled=False,\n",
    "    layout=widgets.Layout(width='fit-parent', height='auto', justify_self='center', align_self='center', min_width='300px'),\n",
    "    rows=5\n",
    ")\n",
    "\n",
    "search_button = widgets.Button(\n",
    "    description='Search',\n",
    "    disabled=False,\n",
    "    button_style='info',\n",
    "    tooltip='Search',\n",
    "    icon='search',\n",
    "    layout=widgets.Layout(width='auto', height='auto')\n",
    ")\n",
    "\n",
    "search_keyword_tag_clr = widgets.HBox([clear_button, search_button], layout=widgets.Layout(align_items='center', width='auto', justify_content='center'))\n",
    "search_keyword_tag_box = widgets.VBox([keywords_label, search_keyword_tag_clr, keyword_description, search_keyword_tag], layout=widgets.Layout(align_items='center', width='auto', justify_content='center'))\n",
    "\n",
    "search_id_box_stack = widgets.AppLayout(\n",
    "    children=[search_id_box, show_all_toggle, show_tree_toggle, show_columns],\n",
    "    grid_gap='10px',\n",
    "    justify_items='center',\n",
    "    align_items='center',\n",
    "    layout=widgets.Layout(width='fit-parent', height='auto', justify_content='center', align_items='center', display='flex', align_content='center', align_self='center', justify_self='center')\n",
    ")\n",
    "\n",
    "showing_number = widgets.Label(\n",
    "    value='Showing 0 items',\n",
    "    layout=widgets.Layout(width='auto', height='auto', justify_content='center', align_items='center', display='flex')\n",
    ")\n",
    "\n",
    "grid = widgets.GridspecLayout(2, 3, align_items='center', height='auto', width='auto', justify_content='center', grid_gap='10px')\n",
    "grid[:, 0] = search_keyword_tag_box\n",
    "grid[0, 1] = search_type_toggle\n",
    "grid[0, 2] = search_abstraction_sel\n",
    "grid[1, 1] = search_columns_sel\n",
    "grid[1, 2] = show_columns\n",
    "\n",
    "tab = widgets.Tab()\n",
    "tab.children = [search_id_box_stack, grid]\n",
    "tab.titles = ['Search by ID', 'Search by Keywords']\n",
    "\n",
    "search_results = widgets.Output(layout=widgets.Layout(width='fit-content', height='auto', padding='0 20px 0 0'))\n",
    "\n",
    "search_type_toggle.add_class('myStyle')\n",
    "search_abstraction_sel.add_class('myStyle')\n",
    "search_columns_sel.add_class('myStyle')\n",
    "keywords_label.add_class('myStyle')\n",
    "show_all_toggle.add_class('myStyle')\n",
    "showing_number.add_class('myStyle')\n",
    "show_tree_toggle.add_class('myStyle')\n",
    "id_label.add_class('myStyle')\n",
    "show_columns.add_class('myStyle')\n",
    "\n",
    "def on_clear_button_clicked(b):\n",
    "    if tab.selected_index == 0:\n",
    "        search_id_tags.value = []\n",
    "    elif tab.selected_index == 1:\n",
    "        search_keyword_tag.value = []\n",
    "        keyword_description.value = ''\n",
    "    \n",
    "def on_search_button_clicked(b):\n",
    "    if tab.selected_index == 1 and keyword_description.value != '':\n",
    "        search_keyword_tag.value = [x[0] for x in custom_kw_extractor.extract_keywords(keyword_description.value)]\n",
    "    \n",
    "def on_update(change):\n",
    "    search_results.clear_output()\n",
    "    column_to_show = list(show_columns.value)\n",
    "    with search_results:\n",
    "        if tab.selected_index==0:\n",
    "            if search_id_tags.value != []:\n",
    "                query_out = get_child_attack_patterns([int(id) for id in search_id_tags.value], attack_pattern_df, show_tree=show_tree_toggle.value, show_columns=column_to_show)\n",
    "                showing_number.value = f\"Showing {len(query_out.values)} items\"\n",
    "                display(capec_abstraction_sort(query_out))\n",
    "            elif show_all_toggle.value:\n",
    "                query_out = attack_pattern_df[column_to_show]\n",
    "                showing_number.value = f\"Showing {len(attack_pattern_df.values)} items\"\n",
    "                display(capec_abstraction_sort(query_out))\n",
    "            else:\n",
    "                showing_number.value = \"Showing 0 items\"\n",
    "        elif tab.selected_index==1 and search_keyword_tag.value != []:\n",
    "            query_out = query_attack_patterns(attack_pattern_df_str, search_columns=search_columns_sel.value, ap_type=search_abstraction_sel.value, keywords=search_keyword_tag.value, query_type=search_type_toggle.value, show_columns=column_to_show)\n",
    "            showing_number.value = f\"Showing {len(query_out.values)} items\"\n",
    "            display(capec_abstraction_sort(query_out))\n",
    "        else:\n",
    "            showing_number.value = \"Showing 0 items\"\n",
    "\n",
    "search_id_tags.observe(on_update, names='value')\n",
    "search_type_toggle.observe(on_update, names='value')\n",
    "search_abstraction_sel.observe(on_update, names='value')\n",
    "search_columns_sel.observe(on_update, names='value')\n",
    "search_keyword_tag.observe(on_update, names='value')\n",
    "show_all_toggle.observe(on_update, names='value')\n",
    "show_tree_toggle.observe(on_update, names='value')\n",
    "show_columns.observe(on_update, names='value')\n",
    "search_button.on_click(on_search_button_clicked)\n",
    "clear_button.on_click(on_clear_button_clicked)\n",
    "tab.observe(on_update, names='selected_index')\n",
    "\n",
    "display(tab)\n",
    "display(showing_number)\n",
    "display(search_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Threat Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "macm_df = read_macm(driver)\n",
    "macm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [],
   "source": [
    "clear_database(driver, \"emacm\")\n",
    "create_enhanched_macm_db(driver, attack_pattern_df, threat_catalog_df, macm_df, macm_file, database=\"emacm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with driver.session(database=\"emacm\") as session:\n",
    "    query_out = session.run(\"MATCH a=((n)-[r1]->(p)) RETURN a\").graph()\n",
    "emacm_graph = GraphWidget(graph=query_out)\n",
    "emacm_graph.directed = True\n",
    "emacm_graph.set_sidebar(enabled=True, start_with=\"Neighborhood\")\n",
    "emacm_graph.set_node_label_mapping(lambda index, node : truncate_string_middle(node[\"properties\"][node_styles.get(node[\"properties\"][\"label\"], {\"label\":\"label\"})[\"label\"]], 15))\n",
    "emacm_graph.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AttackGraphGen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
